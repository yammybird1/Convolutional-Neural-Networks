# import relevant libraries
import torch.nn as nn
import torch
from torch.nn import Conv2d, Sequential, Module, BatchNorm2d, Linear, AdaptiveAvgPool2d
from torch.nn.functional import relu
import torchvision
import torch.utils.data as data
import torchvision.transforms as transforms
import torch.optim as optim
import matplotlib.pyplot as plt


class bottleneck(Module):
    expansion = 4

    def __init__(self, in_channels, out_channels, stride=1, dim_change=None):
        super(bottleneck, self).__init__()

        # declare convolution andnorm layers
        self.conv1 = Conv2d(in_channels, out_channels, kernel_size=1, stride=1)
        self.bn1 = BatchNorm2d(out_channels)
        self.conv2 = Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)
        self.bn2 = BatchNorm2d(out_channels)
        self.conv3 = Conv2d(out_channels, out_channels * self.expansion, kernel_size=1)
        self.bn3 = BatchNorm2d(out_channels * self.expansion)
        self.dim_change = dim_change

    def forward(self, x):
        
        # store residual
        res = x

        output = relu(self.bn1(self.conv1(x)))
        output = relu(self.bn2(self.conv2(output)))
        output = self.bn3(self.conv3(output))

        # downsample residual
        if self.dim_change is not None:
            res = self.dim_change(res)

        # skip connection
        output += res
        output = relu(output)

        return output


class ResNet(Module):
    def __init__(self, block, layers, classes=2):
        super(ResNet, self).__init__()

        self.in_channels = 64

        # first convolution and batch norm in ResNet architecture
        self.conv1 = Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1)
        self.bn1 = BatchNorm2d(self.in_channels)

        # Generate layers
        self.layer1 = self.layer(block, 64, layers[0], stride=1)
        self.layer2 = self.layer(block, 128, layers[1], stride=2)
        self.layer3 = self.layer(block, 256, layers[2], stride=2)
        self.layer4 = self.layer(block, 512, layers[3], stride=2)

        self.avgPool = AdaptiveAvgPool2d(1)
        self.fc = Linear(512 * block.expansion, classes)

    def layer(self, block, out_channels, layers, stride=1):
        dim_change = None

        # create a downsample block
        if stride != 1 or out_channels != self.in_channels * block.expansion:
            dim_change = Sequential(
                Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride),
                BatchNorm2d(out_channels * block.expansion))

        # add first layer
        net_layers = [block(self.in_channels, out_channels, stride=stride, dim_change=dim_change)]

        self.in_channels = out_channels * block.expansion

        # create the 4 layers required for ResNet50
        for i in range(1, layers):  # first layer added previously
            net_layers.append(block(self.in_channels, out_channels))
            self.in_channels = out_channels * block.expansion

        return Sequential(*net_layers)

    def forward(self, x):
        x = relu(self.bn1(self.conv1(x)))

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgPool(x)

        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x
