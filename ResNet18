# import relevant libraries
import torch.nn as nn
import torch
from torch.nn import Conv2d, Sequential, Module, BatchNorm2d, Linear, AdaptiveAvgPool2d
from torch.nn.functional import relu
import torchvision
import torch.utils.data as data
import torchvision.transforms as transforms
import torch.optim as optim
import matplotlib.pyplot as plt

#two 3x3 convolutions
class baseBlock(torch.nn.Module):
    expansion = 1

    def __init__(self, input_planes, planes, stride=1, dim_change=None):
        super(baseBlock, self).__init__()

        # declare convolutional layers with batch norms
        self.conv1 = torch.nn.Conv2d(input_planes, planes, stride=stride, kernel_size=3, padding=1)
        self.bn1 = torch.nn.BatchNorm2d(planes)
        self.conv2 = torch.nn.Conv2d(planes, planes, stride=1, kernel_size=3, padding=1)
        self.bn2 = torch.nn.BatchNorm2d(planes)
        self.dim_change = dim_change

    def forward(self, x):
        # Save the residual
        res = x
        output = relu(self.bn1(self.conv1(x)))
        output = self.bn2(self.conv2(output))

        # downsample residual if dimension change detected
        if self.dim_change is not None:
            res = self.dim_change(res)

        # skip connection
        # ensures learning is preserved
        output += res
        output = relu(output)

        return output


class ResNet(Module):
    def __init__(self, block, layers, classes=2):
        super(ResNet, self).__init__()

        # set input channels to first conv layerto 64
        self.in_channels = 64

        # first convolution and batch norm in ResNet architecture
        self.conv1 = Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1)
        self.bn1 = BatchNorm2d(self.in_channels)

        # Generate layers
        self.layer1 = self.layer(block, 64, layers[0], stride=1)
        self.layer2 = self.layer(block, 128, layers[1], stride=2)
        self.layer3 = self.layer(block, 256, layers[2], stride=2)
        self.layer4 = self.layer(block, 512, layers[3], stride=2)

        self.avgPool = AdaptiveAvgPool2d(1)
        self.fc = Linear(512 * block.expansion, classes)

    def layer(self, block, out_channels, layers, stride=1):
        dim_change = None

        # create a downsample block
        if stride != 1 or out_channels != self.in_channels * block.expansion:
            dim_change = Sequential(
                Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride),
                BatchNorm2d(out_channels * block.expansion))

        # add first layer
        net_layers = [block(self.in_channels, out_channels, stride=stride, dim_change=dim_change)]

        self.in_channels = out_channels * block.expansion

        # create the 4 layers required for ResNet50
        for i in range(1, layers):  # first layer added previously
            net_layers.append(block(self.in_channels, out_channels))
            self.in_channels = out_channels * block.expansion

        return Sequential(*net_layers)

    def forward(self, x):
        x = relu(self.bn1(self.conv1(x)))

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgPool(x)

        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x
